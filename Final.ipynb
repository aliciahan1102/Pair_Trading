{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7e9cca5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import jason"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1787cb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import DBSCAN\n",
    "from datetime import datetime, timedelta\n",
    "from sklearn.metrics.pairwise import manhattan_distances, euclidean_distances\n",
    "from sklearn.cluster import KMeans, AgglomerativeClustering\n",
    "from scipy.spatial.distance import cdist\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "180ce2d1",
   "metadata": {},
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "357d5593",
   "metadata": {},
   "outputs": [],
   "source": [
    "ks_lst_df = pd.read_csv('kospi_list.csv',encoding='CP949')\n",
    "ks_lst_df = ks_lst_df[~((ks_lst_df['구분'] == 10) | (ks_lst_df['구분'] == 12) | (ks_lst_df['구분'] == 17))] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a6a5024",
   "metadata": {},
   "outputs": [],
   "source": [
    "kdq_lst_df = pd.read_csv('kosdaq_list.csv',encoding='CP949')\n",
    "ks_dict = pd.Series(ks_lst_df.종목명.values,index=ks_lst_df.종목코드).to_dict() \n",
    "kdq_dict = pd.Series(kdq_lst_df.종목명.values,index=kdq_lst_df.종목코드).to_dict() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "973c779c",
   "metadata": {},
   "outputs": [],
   "source": [
    "ks_dict.update(kdq_dict)\n",
    "total_dict = ks_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af583dd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from glob import glob\n",
    "stk_lst = glob(r'/Users/eunbihan/Desktop/HY Univ/KORMS/alicia')\n",
    "\n",
    "file_name_lst = []\n",
    "for name in stk_lst:\n",
    "    file_name = name.split('\\\\')[-1].split('.')[0]\n",
    "    if file_name in list(total_dict.keys()):\n",
    "        file_name_lst.append(file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4947e712",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_path2 = \"/Users/eunbihan/Desktop/HY Univ/KORMS/pair_trading/alicia\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbb3d34e",
   "metadata": {},
   "outputs": [],
   "source": [
    "close_df = pd.DataFrame()#pd.DataFrame(columns = list(ks_dict.values()))\n",
    "\n",
    "for file_name in file_name_lst:\n",
    "    temp_df = pd.read_csv(base_path2 + str(file_name) +'.csv',encoding='CP949').set_index('날짜').rename(columns={'종가':file_name})[file_name]#.iloc[:,3:4]\n",
    "    close_df = pd.concat([close_df,temp_df],axis = 1)\n",
    "close_df.index = close_df.index.map(lambda x :str(x).split('.')[0])\n",
    "close_df.index = pd.to_datetime(close_df.index)\n",
    "close_df.to_csv('종가.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "199ce1d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "daily_ret = np.log(close_df/close_df.shift(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26b59365",
   "metadata": {},
   "outputs": [],
   "source": [
    "m_ret = daily_ret.resample('1m').apply(lambda x: x.sum() if len(x[x.notna()])>=15 else np.nan)\n",
    "bw_ret = daily_ret.resample('2w').apply(lambda x: x.sum() if len(x[x.notna()])>=5 else np.nan)\n",
    "w_ret = daily_ret.resample('1w').apply(lambda x: x.sum() if len(x[x.notna()])>=2 else np.nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02b14813",
   "metadata": {},
   "outputs": [],
   "source": [
    "m_ret.to_csv('m_ret.csv')\n",
    "bw_ret.to_csv('bw_ret.csv')\n",
    "w_ret.to_csv('w_ret.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57dbb26c",
   "metadata": {},
   "source": [
    "# Pair_trading_calculator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d228a256",
   "metadata": {},
   "outputs": [],
   "source": [
    "close_df = pd.read_csv('종가.csv',index_col=0)\n",
    "close_df = close_df[close_df.index>'2000-01-01']\n",
    "close_df.index = pd.DatetimeIndex(close_df.index)\n",
    "daily_ret = np.log(close_df/close_df.shift(1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5cbddc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "m_ret = pd.read_csv('m_ret.csv',index_col= 0 )\n",
    "m_ret.index = pd.DatetimeIndex(m_ret.index)\n",
    "bw_ret = pd.read_csv('bw_ret.csv',index_col= 0 )\n",
    "bw_ret.index = pd.DatetimeIndex(bw_ret.index)\n",
    "w_ret = pd.read_csv('w_ret.csv',index_col= 0 )\n",
    "w_ret.index = pd.DatetimeIndex(w_ret.index)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27de2e02",
   "metadata": {},
   "source": [
    "## Data Pre-processing\n",
    "\n",
    "- according to rebalancing interval \n",
    "- input : weekly/bi-weekly/monthly log-return data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e638f15a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def momentum(ret,max_momentum):\n",
    "    if ret.shape[0]<max_momentum:\n",
    "        return \"Length of data is shorter than max_momentum\"\n",
    "    else:\n",
    "        ret = ret.apply(lambda x:x if len(x[x.notna()])>=max_momentum else np.nan)\n",
    "        ret = ret.iloc[-max_momentum:,:].dropna(axis=1)\n",
    "        \n",
    "        col_name = list(pd.Series(['mom']*max_momentum)+pd.Series(list(range(1,max_momentum+1))).astype(str))\n",
    "        etf_list = list(ret.columns)\n",
    "        momentem_df = pd.DataFrame(index = etf_list,columns = col_name)\n",
    "        for etf in etf_list:\n",
    "            momentum_df.loc[etf,'mom1']=ret[etf].iloc[-1]\n",
    "            for j in range(2,max_momentum+1):\n",
    "                mom='mom'+str(j)\n",
    "                momentum_df.loc[etf,mom]=ret[etf].iloc[-j:-1].sum()\n",
    "        return momentum_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1594f1ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# input : momentum data from momentum function\n",
    "\n",
    "def PCA_df(df):\n",
    "    normalized_df = StandardScaler().fit(df)\n",
    "    normalized_df = normalized_df.transform(df)\n",
    "    \n",
    "    pca = PCA()\n",
    "    PCA_df = pca.fit_transform(noramlized_df)\n",
    "    explained_var = pca.explained_variance_ratio_.cumsum()\n",
    "    num_PC = len(explained_var[explained_var<0.99])+1\n",
    "    \n",
    "    final_df = PCA_df[:,:num_PC]\n",
    "    final_df = pd.DataFrame(final_df,index=df.index)\n",
    "    \n",
    "    return final_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e72a06f",
   "metadata": {},
   "source": [
    "## Clustering"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4dbd742e",
   "metadata": {},
   "source": [
    "### 1. K-Means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "83f3920b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def kmeans_w_pct_ol(dataframe,K,percentile):\n",
    "    km = KMeeans(n_clusters=K,max_iter=1000)\n",
    "    km = km.fit(dataframe)\n",
    "    \n",
    "    result = pd.DataFrame(index=dataframe.index)\n",
    "    result['label']=km.labels_\n",
    "    \n",
    "    nearest_dis = pd.DataFrame(euclidean_distances(dataframe)).apply(lambda x:x[x>0].min())\n",
    "    eps = np.percentile(nearest_dis.sort_values(),percentile)\n",
    "    centroids = km.cluster_centers_\n",
    "    \n",
    "    for i in range(K):\n",
    "        results.loc[results['label']==i,'central_dis']=cdist(dataframe.iloc[km.labels_==i],\n",
    "                                                            centroids[i].reshape(1,centroids.shape[1]),'euclidean')\n",
    "    result['OL']=((results['central_dis']-eps)>=0).astype(float)\n",
    "    \n",
    "    return result[['label','OL']]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1281000a",
   "metadata": {},
   "source": [
    "### 2. Agglomerative Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e807a700",
   "metadata": {},
   "outputs": [],
   "source": [
    "def AG_cluster(dataframe,percentile):\n",
    "    dis = pd.DataFrame(manhattan_distances(dataframe)).apply(lambda x:x[x>0].min()).sort_values()\n",
    "    eps = np.percentile(dis,percentile)\n",
    "    ag_cluster = AgglomerativeClustering(n_clusters=None,affinity = 'l1',\n",
    "                                         linkage='average',distance_threshold=eps).fit(dataframe)\n",
    "    result = pd.DataFrame(ag_cluster.labels_,index=dataframe.index,columns=['label'])\n",
    "    \n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecbe7168",
   "metadata": {},
   "source": [
    "### 3. DBscan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d71ba8a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dbscan(dataframe,percentile):\n",
    "    minpts = round(np.log(dataframe.shape[0]))\n",
    "    dis = pd.DataFrame(manhattan_distances(dataframe)).apply(lambda x:x[x>0].sort_values()[:minpts].mean()).sort_values()\n",
    "    eps = np.percentile(dis,percentile)\n",
    "    db_cluster = DBSCAN(eps = eps, min_samples=minpts,\n",
    "                       metric = 'l1').fit(dataframe)\n",
    "    result = pd.DataFrame(db_cluster.labels_,index=dataframe.index,\n",
    "                         columns=['label'])\n",
    "    result.loc[result['label']<0,'OL']=1\n",
    "    result.loc[results['label']>=0,'OL']=0\n",
    "    \n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64db50e2",
   "metadata": {},
   "source": [
    "#### Stocks in Portfolio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2577fe3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#stocks in portfolio\n",
    "\n",
    "def portfolio_generation(momentum_df, cluster_df):\n",
    "\n",
    "\n",
    "    if cluster_df.shape[1]==2:\n",
    "        non_outlier = cluster_df[cluster_df['OL']==0]\n",
    "    else:\n",
    "        non_outlier = cluster_df\n",
    "    \n",
    "    cluster_list = list(non_outlier['label'].unique())    \n",
    "    K = len(cluster_list)\n",
    "    LONG = []\n",
    "    SHORT = []\n",
    "    diff_ = []\n",
    "    for i in range(K):\n",
    "        cur_cluster = cluster_list[i]\n",
    "        \n",
    "        temp_df_ = momentum_df.loc[list(non_outlier[non_outlier['label']==cur_cluster].index),'mom1']\n",
    "        if len(temp_df_)==1:\n",
    "            continue\n",
    "        temp_df_ = temp_df_.sort_values()\n",
    "        \n",
    "\n",
    "        temp_long_ = temp_df_.iloc[:int(temp_df_.shape[0]/2)]\n",
    "        temp_short_ = temp_df_.iloc[-int(temp_df_.shape[0]/2):]\n",
    "\n",
    "        for j in range(len(temp_long_)):\n",
    "            diff_ = diff_ + [temp_short_.iloc[-(j+1)]-temp_long_.iloc[j]]\n",
    "    \n",
    "    if len(diff_)==0:\n",
    "        return LONG,SHORT\n",
    "\n",
    "    diff_cut = pd.Series(diff_).std()\n",
    "\n",
    "    for i in range(K):\n",
    "        cur_cluster = cluster_list[i]\n",
    "        \n",
    "        temp_df = momentum_df.loc[list(non_outlier[non_outlier['label']==cur_cluster].index),'mom1']\n",
    "        if len(temp_df)==1:\n",
    "            continue\n",
    "        temp_df = temp_df.sort_values()\n",
    "        \n",
    "\n",
    "        temp_long = temp_df.iloc[:int(temp_df.shape[0]/2)]\n",
    "        temp_short = temp_df.iloc[-int(temp_df.shape[0]/2):]\n",
    "\n",
    "        for j in range(len(temp_long)):\n",
    "            if (temp_short.iloc[-(j+1)]-temp_long.iloc[j])>diff_cut:\n",
    "                LONG = LONG + [temp_long.index[j]]\n",
    "                SHORT = SHORT + [temp_short.index[-(j+1)]]\n",
    "\n",
    "    return LONG,SHORT"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6871fcc",
   "metadata": {},
   "source": [
    "### Calcualte Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "498d07b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#extract performance\n",
    "def performance(daily_ret,ret,max_momentum,K,percentile, cluster):\n",
    "\n",
    "    performance_df = pd.DataFrame()\n",
    "    portfolio_weight = pd.DataFrame(columns = ret.columns)\n",
    "\n",
    "    for i in range(max_momentum,ret.shape[0]-1):\n",
    "        reb_date = ret.index[i]\n",
    "        next_reb_date = ret.index[i+1]\n",
    "        temp_ret = ret[ret.index<=reb_date]\n",
    "        momentum_df = momentum(temp_ret, max_momentum)\n",
    "        final_df = PCA_df(momentum_df)\n",
    "        if cluster =='km':\n",
    "            cluster_df = kmeans_w_pct_ol(final_df, K, percentile)\n",
    "        elif cluster =='db':\n",
    "            cluster_df = dbscan(final_df, percentile)\n",
    "        elif cluster =='kmd':\n",
    "            cluster_df = Kmedoid_o(final_df , K ,percentile)\n",
    "        else:\n",
    "            cluster_df = AG_cluster(final_df, percentile)\n",
    "        long_short = portfolio_generation(momentum_df,cluster_df)\n",
    "        long = long_short[0]\n",
    "        short = long_short[1]\n",
    "        temp_return = (daily_ret.loc[(daily_ret.index<=next_reb_date)&(daily_ret.index>reb_date),long].sum(axis=1)\\\n",
    "                        -daily_ret.loc[(daily_ret.index<=next_reb_date)&(daily_ret.index>reb_date),short].sum(axis=1))/len(long)\n",
    "\n",
    "        temp_return = temp_return.fillna(0)\n",
    "\n",
    "        performance_df = pd.concat([performance_df,temp_return])\n",
    "        if len(long)>0:\n",
    "            portfolio_weight.loc[reb_date,long] = 1/len(long)\n",
    "            portfolio_weight.loc[reb_date,short] = -1/len(short)\n",
    "        else:\n",
    "            portfolio_weight.loc[reb_date] = 0\n",
    "  \n",
    "    return performance_df,portfolio_weight.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0339e613",
   "metadata": {},
   "outputs": [],
   "source": [
    "iter_dir = 'result\\\\monthly_db\\\\'\n",
    "\n",
    "i=0\n",
    "#Kmeans\n",
    "#cluster_list = [5,10,20,25]\n",
    "mom_list = [12,24,48]\n",
    "percentile_list = [10,20,30,40,50,60,70,80,90]\n",
    "cl=0\n",
    "all_per = pd.DataFrame()\n",
    "for mom in mom_list:\n",
    "    #for cl in cluster_list:\n",
    "        for pct in percentile_list:\n",
    "            temp = performance(daily_ret,m_ret,mom,cl,pct,'db')\n",
    "            temp_per = pd.DataFrame(temp[0])\n",
    "            \n",
    "            temp_per.columns=[str(mom)+'-'+str(pct)]\n",
    "            temp_dir = iter_dit + str(mom)+'-'+str(pct)+'.csv'\n",
    "            \n",
    "            temp[1].to_csv(temp_dir)\n",
    "            all_per = pd.concat([all_per,temp_per],axis=1)\n",
    "            all_per.to_csv('monthly_db_per.csv') #weekly_km_per24.csv / weekly ~~"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e30f7081",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
